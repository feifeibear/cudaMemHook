## TurboHooker Design Doc

TurboHooker是一个GPU多进程内存管工具。
由于cuda内存分配释放开销很大，GPU上的显存管理是一个尚未完全解决的开放问题。
具体到深度学习应用场景，在单个GPU上服务多个模型并没有最佳方案。比如：

如何单进程处理变化的显存需求，变输入的DNN模型推理过程的中间内存张量尺寸不断变化，需要利用缓存策略避免频繁内存分配释放开销。

如何处理多进程变化的内存需求，每个进程一个单独分配器会导致进程启动时候分配内存开销巨大，另外，多进程内存使用很容易爆掉。
比如某FAQ服务需要同时加载14个模型服务不同类型的请求，这种情况下显存的空间无法满足其需求。这时候，最好把多进程内存统一管理。

由于单个进程往往无法充分利用GPU的计算资源，在单GPU上运行多个进程理论上是更明智的选择。但是GPU上切换进程开销十分巨大，其中为新进程进行内存分配和释放是开销中的很大一部分。
TurboHooker采用client-server模式，server是一个守护进程(deamon)，在启动时候预先将GPU的全部内存分配出来。TurboHooker拦截client的内存分配请求，将内存分配尺寸信息发送给server，server运行一个调度器来寻找空闲的连续地址。TurboHooker拦截client的内存释放请求，调度器将连续地址空间标记为空闲。

### Server调度算法
可以参考best fit类型算法，也可以结合问题特点实现model-aware的算法。

### Server-Client通信
GPU简称间通信使用cuda ipc，但是cuda ipc相比cpu ipc要低效很多。client启动后，通过cuda ipc通信一次cuda ipc的mem handler，之后的client向server发送需要分配的内存尺寸，server向client发送分配的地址偏移。

### 隐私
不同进程之间地址应该隔离，避免进程通过越界地址访问其他进程的地址空间。有待思考。

### 应用场景
最典型场景是单机多进程推理服务，训练任务和推理任务混合调度。
